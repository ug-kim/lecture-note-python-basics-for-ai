{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "4_fancy_rnn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0M47aJDTXtbL"
      },
      "source": [
        "##**4. LSTM, GRU**\r\n",
        "1. 기존 RNN과 다른 부분에 대해서 배웁니다.\r\n",
        "2. 이전 실습에 이어 다양한 적용법을 배웁니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaYg8bTFTTNp",
        "outputId": "ee1be30f-fca5-46d6-da22-96f72cc74322"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBoAWPAJSI2D"
      },
      "source": [
        "### **필요 패키지 import**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEnlDHarWusL"
      },
      "source": [
        "from tqdm import tqdm\r\n",
        "from torch import nn\r\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\r\n",
        "\r\n",
        "import torch"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sze4MVwxSYPR"
      },
      "source": [
        "### **데이터 전처리**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugKWDpQrSY3o"
      },
      "source": [
        "아래의 sample data를 확인해봅시다.  \r\n",
        "이전 실습과 동일합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWjwZOmGYMhw"
      },
      "source": [
        "vocab_size = 100\r\n",
        "pad_id = 0\r\n",
        "\r\n",
        "data = [\r\n",
        "  [85,14,80,34,99,20,31,65,53,86,3,58,30,4,11,6,50,71,74,13],\r\n",
        "  [62,76,79,66,32],\r\n",
        "  [93,77,16,67,46,74,24,70],\r\n",
        "  [19,83,88,22,57,40,75,82,4,46],\r\n",
        "  [70,28,30,24,76,84,92,76,77,51,7,20,82,94,57],\r\n",
        "  [58,13,40,61,88,18,92,89,8,14,61,67,49,59,45,12,47,5],\r\n",
        "  [22,5,21,84,39,6,9,84,36,59,32,30,69,70,82,56,1],\r\n",
        "  [94,21,79,24,3,86],\r\n",
        "  [80,80,33,63,34,63],\r\n",
        "  [87,32,79,65,2,96,43,80,85,20,41,52,95,50,35,96,24,80]\r\n",
        "]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmqlfxW_Tsfm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4cb7ec8-5df9-4e40-8c51-25f63dd9c18f"
      },
      "source": [
        "max_len = len(max(data, key=len))\r\n",
        "print(f\"Maximum sequence length: {max_len}\")\r\n",
        "\r\n",
        "valid_lens = []\r\n",
        "for i, seq in enumerate(tqdm(data)):\r\n",
        "  valid_lens.append(len(seq))\r\n",
        "  if len(seq) < max_len:\r\n",
        "    data[i] = seq + [pad_id] * (max_len - len(seq))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 8333.61it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Maximum sequence length: 20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znWCR7UbTvVE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8687c273-7561-4831-9b1e-3e90e82eebf2"
      },
      "source": [
        "# B: batch size, L: maximum sequence length\r\n",
        "batch = torch.LongTensor(data)  # (B, L)\r\n",
        "batch_lens = torch.LongTensor(valid_lens)  # (B)\r\n",
        "\r\n",
        "batch_lens, sorted_idx = batch_lens.sort(descending=True)\r\n",
        "batch = batch[sorted_idx]\r\n",
        "\r\n",
        "print(batch)\r\n",
        "print(batch_lens)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[85, 14, 80, 34, 99, 20, 31, 65, 53, 86,  3, 58, 30,  4, 11,  6, 50, 71,\n",
            "         74, 13],\n",
            "        [58, 13, 40, 61, 88, 18, 92, 89,  8, 14, 61, 67, 49, 59, 45, 12, 47,  5,\n",
            "          0,  0],\n",
            "        [87, 32, 79, 65,  2, 96, 43, 80, 85, 20, 41, 52, 95, 50, 35, 96, 24, 80,\n",
            "          0,  0],\n",
            "        [22,  5, 21, 84, 39,  6,  9, 84, 36, 59, 32, 30, 69, 70, 82, 56,  1,  0,\n",
            "          0,  0],\n",
            "        [70, 28, 30, 24, 76, 84, 92, 76, 77, 51,  7, 20, 82, 94, 57,  0,  0,  0,\n",
            "          0,  0],\n",
            "        [19, 83, 88, 22, 57, 40, 75, 82,  4, 46,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0],\n",
            "        [93, 77, 16, 67, 46, 74, 24, 70,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0],\n",
            "        [94, 21, 79, 24,  3, 86,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0],\n",
            "        [80, 80, 33, 63, 34, 63,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0],\n",
            "        [62, 76, 79, 66, 32,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0]])\n",
            "tensor([20, 18, 18, 17, 15, 10,  8,  6,  6,  5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPRtdhHoUKhH"
      },
      "source": [
        "### **LSTM 사용**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1FvfENCUqYN"
      },
      "source": [
        "LSTM에선 cell state가 추가됩니다.  \r\n",
        "Cell state의 shape는 hidden state의 그것과 동일합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q76VGoCCUrcQ"
      },
      "source": [
        "embedding_size = 256\r\n",
        "hidden_size = 512\r\n",
        "num_layers = 1\r\n",
        "num_dirs = 1\r\n",
        "\r\n",
        "embedding = nn.Embedding(vocab_size, embedding_size)\r\n",
        "lstm = nn.LSTM(\r\n",
        "    input_size=embedding_size,\r\n",
        "    hidden_size=hidden_size,\r\n",
        "    num_layers=num_layers,\r\n",
        "    bidirectional=True if num_dirs > 1 else False\r\n",
        ")\r\n",
        "\r\n",
        "h_0 = torch.zeros((num_layers * num_dirs, batch.shape[0], hidden_size))  # (num_layers * num_dirs, B, d_h)\r\n",
        "c_0 = torch.zeros((num_layers * num_dirs, batch.shape[0], hidden_size))  # (num_layers * num_dirs, B, d_h)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhS7qvIKWYYb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "635a3004-7aa6-4bcf-c5b6-de585616caef"
      },
      "source": [
        "# d_w: word embedding size\r\n",
        "batch_emb = embedding(batch)  # (B, L, d_w)\r\n",
        "\r\n",
        "packed_batch = pack_padded_sequence(batch_emb.transpose(0, 1), batch_lens)\r\n",
        "\r\n",
        "packed_outputs, (h_n, c_n) = lstm(packed_batch, (h_0, c_0))\r\n",
        "print(packed_outputs)\r\n",
        "print(packed_outputs[0].shape)\r\n",
        "print(h_n.shape)\r\n",
        "print(c_n.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PackedSequence(data=tensor([[ 0.0297, -0.0759,  0.1151,  ..., -0.0262, -0.1328, -0.1900],\n",
            "        [-0.0824, -0.0088, -0.1594,  ...,  0.0691,  0.0334, -0.1163],\n",
            "        [-0.0782,  0.1323,  0.0554,  ...,  0.0391, -0.0544, -0.1738],\n",
            "        ...,\n",
            "        [ 0.0439,  0.1663, -0.0978,  ..., -0.0538,  0.0549, -0.0498],\n",
            "        [ 0.0488,  0.0062, -0.0236,  ..., -0.0676,  0.1770, -0.0364],\n",
            "        [-0.0587, -0.0118,  0.0083,  ..., -0.0900,  0.0264,  0.0454]],\n",
            "       grad_fn=<CatBackward>), batch_sizes=tensor([10, 10, 10, 10, 10,  9,  7,  7,  6,  6,  5,  5,  5,  5,  5,  4,  4,  3,\n",
            "         1,  1]), sorted_indices=None, unsorted_indices=None)\n",
            "torch.Size([123, 512])\n",
            "torch.Size([1, 10, 512])\n",
            "torch.Size([1, 10, 512])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArOrgjHjZqAa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "418f2346-c53a-43dc-99b0-2ff7f6b1e3bc"
      },
      "source": [
        "# packed output을 원래 모양으로\r\n",
        "\r\n",
        "outputs, output_lens = pad_packed_sequence(packed_outputs)\r\n",
        "print(outputs.shape)\r\n",
        "print(output_lens)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([20, 10, 512])\n",
            "tensor([20, 18, 18, 17, 15, 10,  8,  6,  6,  5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meuNwIIn-H-g"
      },
      "source": [
        "### **GRU 사용**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMUysrtLihqt"
      },
      "source": [
        "GRU는 cell state가 없어 RNN과 동일하게 사용 가능합니다.   \r\n",
        "GRU를 이용하여 LM task를 수행해봅시다.\r\n",
        "- LM : Language Modeling\r\n",
        "- 전체 sequence를 통으로 RNN에 넣지 말고 순차적으로 한 time step씩 생성해 다음 time step에 넣어줘야 한다\r\n",
        "- for loop을 돌아야 한다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHw8PSf--lVg"
      },
      "source": [
        "gru = nn.GRU(\r\n",
        "    input_size=embedding_size,\r\n",
        "    hidden_size=hidden_size,\r\n",
        "    num_layers=num_layers,\r\n",
        "    bidirectional=True if num_dirs > 1 else False\r\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbMy2CkWzobD"
      },
      "source": [
        "output_layer = nn.Linear(hidden_size, vocab_size)\r\n",
        "\r\n",
        "# 가장 큰 값 가지는 index 추출\r\n",
        "# vocab 내에서 정답으로 선택될 확률 높은 단어"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YavlcFZywCBK"
      },
      "source": [
        "# input_id : 처음 단어\r\n",
        "# 처음에는 단어 하나로 시작\r\n",
        "input_id = batch.transpose(0, 1)[0, :]  # (B)\r\n",
        "hidden = torch.zeros((num_layers * num_dirs, batch.shape[0], hidden_size))  # (1, B, d_h)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1tFGyvo-uHb"
      },
      "source": [
        "Teacher forcing 없이 이전에 얻은 결과를 다음 input으로 이용합니다.\r\n",
        "- Teacher forcing : 처음에는 이전에 생성된 단어들이 아닌 GT 단어들을 넣어준다\r\n",
        "\r\n",
        "- 모델이 이 단어들을 생성했다고 가정하고 cheating을 해준다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6HRC3TAxtGa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34bff141-e3af-44b6-a348-c2a5731ba62c"
      },
      "source": [
        "for t in range(max_len):\r\n",
        "  # unsqueeze -> 모양을 (1, )으로 맞춰주기 위해\r\n",
        "  input_emb = embedding(input_id).unsqueeze(0)  # (1, B, d_w)\r\n",
        "\r\n",
        "  # rnn model 안에는 자체적으로 길이만큼 for문을 돌도록 구현\r\n",
        "  # 길이 1짜리 input을 넣었으니\r\n",
        "  # cell 하나 통과한 것과 똑같은 결과\r\n",
        "  output, hidden = gru(input_emb, hidden)  # output: (1, B, d_h), hidden: (1, B, d_h)\r\n",
        "\r\n",
        "  # V: vocab size\r\n",
        "  output = output_layer(output)  # (1, B, V)\r\n",
        "  probs, top_id = torch.max(output, dim=-1)  # probs: (1, B), top_id: (1, B)\r\n",
        "\r\n",
        "  print(\"*\" * 50)\r\n",
        "  print(f\"Time step: {t}\")\r\n",
        "  print(output.shape)\r\n",
        "  print(probs.shape)\r\n",
        "  print(top_id.shape)\r\n",
        "\r\n",
        "  input_id = top_id.squeeze(0)  # (B)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "**************************************************\n",
            "Time step: 0\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 1\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 2\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 3\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 4\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 5\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 6\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 7\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 8\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 9\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 10\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 11\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 12\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 13\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 14\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 15\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 16\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 17\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 18\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 19\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WY3vh9Cm4KaH"
      },
      "source": [
        "`max_len`만큼의 for 문을 돌면서 모든 결과물의 모양을 확인했지만 만약 종료 조건(예를 들어 문장의 끝을 나타내는 end token 등)이 되면 중간에 생성을 그만둘 수도 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l07L_QncemE7"
      },
      "source": [
        "### **양방향 및 여러 layer 사용**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lasjjz-teohw"
      },
      "source": [
        "이번엔 양방향 + 2개 이상의 layer를 쓸 때 얻을 수 있는 결과에 대해 알아봅니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEy00WX3ghsb"
      },
      "source": [
        "num_layers = 2\r\n",
        "num_dirs = 2\r\n",
        "dropout=0.1\r\n",
        "\r\n",
        "gru = nn.GRU(\r\n",
        "    input_size=embedding_size,\r\n",
        "    hidden_size=hidden_size,\r\n",
        "    num_layers=num_layers,\r\n",
        "    dropout=dropout,\r\n",
        "    bidirectional=True if num_dirs > 1 else False\r\n",
        ")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QX4LVL_Ag4kK"
      },
      "source": [
        "Bidirectional이 되었고 layer의 개수가 $2$로 늘었기 때문에 hidden state의 shape도 `(4, B, d_h)`가 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8aBk8yrfOHU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b90c193a-d004-4d44-925f-5a2eab18915f"
      },
      "source": [
        "# d_w: word embedding size, num_layers: layer의 개수, num_dirs: 방향의 개수\r\n",
        "batch_emb = embedding(batch)  # (B, L, d_w)\r\n",
        "h_0 = torch.zeros((num_layers * num_dirs, batch.shape[0], hidden_size))  # (num_layers * num_dirs, B, d_h) = (4, B, d_h)\r\n",
        "\r\n",
        "# 4의 의미\r\n",
        "# 첫번째 layer의 forward dir, backward dir\r\n",
        "# 두번째 layer의 forward dir, backward dir\r\n",
        "# 이 순서대로 붙어서 들어가 있다\r\n",
        "\r\n",
        "packed_batch = pack_padded_sequence(batch_emb.transpose(0, 1), batch_lens)\r\n",
        "\r\n",
        "packed_outputs, h_n = gru(packed_batch, h_0)\r\n",
        "print(packed_outputs)\r\n",
        "print(packed_outputs[0].shape)\r\n",
        "print(h_n.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PackedSequence(data=tensor([[-0.0957, -0.0166,  0.0554,  ...,  0.1023,  0.1899,  0.0544],\n",
            "        [-0.0686,  0.0301, -0.1713,  ...,  0.0457,  0.0056,  0.1121],\n",
            "        [ 0.1350, -0.1133, -0.1373,  ..., -0.0269, -0.0185,  0.1510],\n",
            "        ...,\n",
            "        [ 0.0790, -0.0945, -0.0058,  ...,  0.0794,  0.1932, -0.0285],\n",
            "        [-0.0788,  0.1639, -0.2551,  ...,  0.1163,  0.0133,  0.0524],\n",
            "        [-0.0872,  0.2172, -0.2684,  ...,  0.0447,  0.0283,  0.0189]],\n",
            "       grad_fn=<CatBackward>), batch_sizes=tensor([10, 10, 10, 10, 10,  9,  7,  7,  6,  6,  5,  5,  5,  5,  5,  4,  4,  3,\n",
            "         1,  1]), sorted_indices=None, unsorted_indices=None)\n",
            "torch.Size([123, 1024])\n",
            "torch.Size([4, 10, 512])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQdVtMcehndm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e337a01-465a-437f-ad37-dfd86d37e8ca"
      },
      "source": [
        "outputs, output_lens = pad_packed_sequence(packed_outputs)\r\n",
        "\r\n",
        "print(outputs.shape)  # (L, B, num_dirs*d_h)\r\n",
        "print(output_lens)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([20, 10, 1024])\n",
            "tensor([20, 18, 18, 17, 15, 10,  8,  6,  6,  5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byuggMjekUxS"
      },
      "source": [
        "각각의 결과물의 shape는 다음과 같습니다.\r\n",
        "\r\n",
        "`outputs`: `(max_len, batch_size, num_dir * hidden_size)`  \r\n",
        "`h_n`: `(num_layers*num_dirs, batch_size, hidden_size)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaXhvyHjmFR3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3e43fe7-8caa-48b3-e57e-8b9634661364"
      },
      "source": [
        "batch_size = h_n.shape[1]\r\n",
        "\r\n",
        "# view로 layer와 dir 분리\r\n",
        "print(h_n.view(num_layers, num_dirs, batch_size, hidden_size))\r\n",
        "print(h_n.view(num_layers, num_dirs, batch_size, hidden_size).shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[[ 0.0522,  0.4401,  0.4628,  ...,  0.2844, -0.4757,  0.3456],\n",
            "          [-0.1115, -0.0468,  0.2259,  ..., -0.4771, -0.1255,  0.1242],\n",
            "          [ 0.0437, -0.1632, -0.2602,  ...,  0.1415, -0.3525, -0.0825],\n",
            "          ...,\n",
            "          [ 0.3407,  0.3344,  0.0991,  ...,  0.0916, -0.0726,  0.1108],\n",
            "          [ 0.2581, -0.0370, -0.2818,  ..., -0.3138,  0.0598, -0.2039],\n",
            "          [-0.1595,  0.1253, -0.1541,  ...,  0.0755,  0.1521,  0.2902]],\n",
            "\n",
            "         [[ 0.2018,  0.0676, -0.1078,  ..., -0.3864, -0.3038,  0.0344],\n",
            "          [ 0.0385,  0.1270,  0.3818,  ...,  0.1379,  0.0512,  0.2351],\n",
            "          [ 0.1968,  0.3757,  0.2424,  ..., -0.1083, -0.0856,  0.1605],\n",
            "          ...,\n",
            "          [-0.2493, -0.0898,  0.0983,  ...,  0.2959,  0.1349,  0.4911],\n",
            "          [ 0.3874,  0.0045, -0.3001,  ..., -0.3361,  0.3570,  0.2867],\n",
            "          [-0.0103,  0.4331, -0.3085,  ..., -0.1546, -0.2151, -0.2990]]],\n",
            "\n",
            "\n",
            "        [[[-0.0872,  0.2172, -0.2684,  ...,  0.0392, -0.0930,  0.1418],\n",
            "          [-0.1356,  0.0282, -0.0698,  ..., -0.1013, -0.0507,  0.0137],\n",
            "          [ 0.0790, -0.0945, -0.0058,  ..., -0.1809,  0.1548, -0.1777],\n",
            "          ...,\n",
            "          [ 0.2698,  0.1056, -0.0996,  ..., -0.2372,  0.0676,  0.0127],\n",
            "          [-0.0916, -0.1796,  0.1632,  ..., -0.3224,  0.0897, -0.0688],\n",
            "          [ 0.0915,  0.0317, -0.1157,  ...,  0.1099,  0.0573,  0.1376]],\n",
            "\n",
            "         [[-0.0011, -0.1966, -0.0786,  ...,  0.1023,  0.1899,  0.0544],\n",
            "          [ 0.0175, -0.0085, -0.1896,  ...,  0.0457,  0.0056,  0.1121],\n",
            "          [-0.3438,  0.0524,  0.0693,  ..., -0.0269, -0.0185,  0.1510],\n",
            "          ...,\n",
            "          [-0.0612, -0.1549,  0.1857,  ..., -0.1409,  0.0673,  0.0256],\n",
            "          [ 0.2690, -0.1389, -0.2169,  ..., -0.0492,  0.2370, -0.0315],\n",
            "          [-0.1017, -0.1011,  0.0841,  ..., -0.0399, -0.2624, -0.0019]]]],\n",
            "       grad_fn=<ViewBackward>)\n",
            "torch.Size([2, 2, 10, 512])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkVWagNQavIq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}